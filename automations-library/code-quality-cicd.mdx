---
title: "Code Quality & CI/CD"
description: "Monitor and improve code quality, automate CI/CD workflows, and handle build failures"
---

## Overview

Code quality and CI/CD automations help maintain high standards and reduce manual intervention when builds fail. These automations can detect issues, attempt fixes, and keep your development workflow smooth.

---

## Example: CI Failure Auto-Fix Monitor

**Use Case**: Automatically detect and attempt to fix failing CI checks on pull requests.

**How it works**:
- Monitors pull requests for failing CI checks
- Analyzes failure logs to understand the issue
- Attempts to fix common issues (linting, formatting, type errors)
- Pushes fixes to the PR branch
- Comments on the PR with what was fixed

**Trigger**: PR check failure webhook

**Prompt Template**:

```text
A CI check has failed on PR #{pr_number}.

1. Fetch the CI logs for the failing check
2. Analyze the error messages to determine the type of failure:
   - Linting errors
   - Type errors
   - Test failures
   - Build errors

3. If it's an auto-fixable issue (linting, formatting):
   - Clone the PR branch
   - Run the appropriate fix command (pnpm run lint --fix, pnpm run pretty)
   - Commit and push the fixes
   - Comment on the PR: "ðŸ¤– Automatically fixed {issue_type}"

4. If it's not auto-fixable:
   - Comment on the PR with a summary of the error
   - Tag the PR author
   - Suggest potential solutions based on the error

5. Update the PR status comment to show Tembo is working on it
```

**MCP Servers Needed**: GitHub, Linear

**Safety Considerations**:
- Only auto-fix low-risk issues (formatting, linting)
- Always commit fixes separately with clear messages
- Never auto-fix test failures or build errors without human review

---

## Tips for Code Quality & CI/CD Automations

- **Start with low-risk fixes**: Only auto-fix formatting and linting issues initiallyâ€”these won't break functionality.
- **Always notify the team**: Leave clear comments explaining what was fixed and why.
- **Set clear boundaries**: Define explicitly what can and cannot be auto-fixed (never auto-fix failing tests without human review).
- **Track success rates**: Monitor auto-fix success vs manual intervention to improve prompts over time.
- **Integrate with issue tracking**: Auto-create tickets in Linear or Jira for issues that can't be auto-fixed.
